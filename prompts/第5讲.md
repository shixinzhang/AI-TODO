
```
import OpenAI from 'openai';

const client = new OpenAI({ apiKey: "sk-xxx" });

const response = await client.chat.completions.create({ model: "gpt-4", messages: [{ role: "user", content: "你好" }] });
```

```
import OpenAI from 'openai';



// 调用 DeepSeek

const client = new OpenAI({

apiKey: "your-deepseek-key",

baseURL: "https://api.deepseek.com"

});



// 调用阿里通义千问

const client = new OpenAI({

apiKey: "your-qwen-key",

baseURL: "https://dashscope.aliyuncs.com/compatible-mode/v1"

});



// 调用字节豆包

const client = new OpenAI({

apiKey: "your-doubao-key",

baseURL: "https://ark.cn-beijing.volces.com/api/v3"

});
```

```javascript

import OpenAI from 'openai';



const client = new OpenAI({

apiKey: process.env.DEEPSEEK_API_KEY,

baseURL: "https://api.deepseek.com"

});



// 场景 1：代码生成、数学计算、JSON 提取 → Temperature = 0

const response1 = await client.chat.completions.create({

model: "deepseek-chat",

messages: [{ role: "user", content: "用 JavaScript 写一个快速排序" }],

temperature: 0 // 绝对理性，确保输出稳定

});



// 场景 2：文案创作、角色扮演、头脑风暴 → Temperature = 0.7-0.9

const response2 = await client.chat.completions.create({

model: "deepseek-chat",

messages: [{ role: "user", content: "写一段科幻小说的开头" }],

temperature: 0.8 // 高创意，输出更有想象力

});

```


```javascript

// ✅ 推荐：只调 Temperature

const response = await client.chat.completions.create({

model: "deepseek-chat",

messages: [{ role: "user", content: "你好" }],

temperature: 0.7,

top_p: 1.0 // 保持默认

});



// ❌ 不推荐：同时调整两个参数

const response = await client.chat.completions.create({

model: "deepseek-chat",

messages: [{ role: "user", content: "你好" }],

temperature: 0.7,

top_p: 0.9 // 逻辑会混乱

});

```

```javascript

// 场景 1：简短回答（如客服机器人）

const response1 = await client.chat.completions.create({

model: "deepseek-chat",

messages: [{ role: "user", content: "什么是 AI？" }],

max_tokens: 100 // 限制在 100 个 token 以内

});



// 场景 2：长文本生成（如文章创作）

const response2 = await client.chat.completions.create({

model: "deepseek-chat",

messages: [{ role: "user", content: "写一篇关于 AI 的文章" }],

max_tokens: 4096 // 允许更长的输出

});

```

```javascript

// 调试阶段：固定 Seed，确保输出可复现

const response1 = await client.chat.completions.create({

model: "deepseek-chat",

messages: [{ role: "user", content: "写一个产品介绍" }],

temperature: 0.7,

seed: 12345 // 固定随机种子

});



// 第二次调用，输出结果会完全一样

const response2 = await client.chat.completions.create({

model: "deepseek-chat",

messages: [{ role: "user", content: "写一个产品介绍" }],

temperature: 0.7,

seed: 12345 // 相同的 Seed，相同的输出

});

```


```javascript

// 通过硅基流动调用 DeepSeek（更稳定）

const client = new OpenAI({

apiKey: process.env.SILICONFLOW_API_KEY,

baseURL: "https://api.siliconflow.cn/v1"

});



const response = await client.chat.completions.create({

model: "deepseek-ai/DeepSeek-V3",

messages: [{ role: "user", content: "你好" }]

});

```

```javascript

// 硅基流动的免费模型调用

const client = new OpenAI({

apiKey: process.env.SILICONFLOW_API_KEY,

baseURL: "https://api.siliconflow.cn/v1"

});



const response = await client.chat.completions.create({

model: "Qwen/Qwen2.5-7B-Instruct", // 完全免费

messages: [{ role: "user", content: "你好" }]

});

```

```javascript

// 调用 Qwen-Long 处理超长文档

const client = new OpenAI({

apiKey: process.env.QWEN_API_KEY,

baseURL: "https://dashscope.aliyuncs.com/compatible-mode/v1"

});



const response = await client.chat.completions.create({

model: "qwen-long",

messages: [{ role: "user", content: "请分析这份 100 页的合同..." }],
max_tokens=4096,  # 限制输出长度

});

```

```javascript

// 调用火山方舟豆包模型

const client = new OpenAI({

apiKey: process.env.DOUBAO_API_KEY,

baseURL: "https://ark.cn-beijing.volces.com/api/v3"

});



const response = await client.chat.completions.create({

model: "doubao-seed-1.6-flash",

messages: [{ role: "user", content: "你好" }]

});

```

## 4.5 

```javascript

// 调用腾讯混元（免费模型）

const client = new OpenAI({

apiKey: process.env.HUNYUAN_API_KEY,

baseURL: "https://api.hunyuan.cloud.tencent.com/v1"

});



const response = await client.chat.completions.create({

model: "hunyuan-lite", // 完全免费

messages: [{ role: "user", content: "你好" }]

});

```

# 5

```javascript

import pRetry from 'p-retry';

import OpenAI from 'openai';



const client = new OpenAI({

	apiKey: process.env.DEEPSEEK_API_KEY,
	
	baseURL: "https://api.deepseek.com",
	
	timeout: 120000 // 超时设置：120 秒
	
	});



async function callLLM(prompt) {

	return pRetry(
	
		async () => {
		
			const response = await client.chat.completions.create({
			
			model: "deepseek-chat",
			
			messages: [{ role: "user", content: prompt }]
			
			});
			
			return response.choices[0].message.content;
		
		},
	
		{
		
			retries: 3, // 最多重试 3 次
			
			factor: 2, // 指数因子
			
			minTimeout: 1000, // 最小延迟 1 秒
			
			maxTimeout: 10000, // 最大延迟 10 秒
			
			onFailedAttempt: (error) => {
			
			console.log(`尝试 ${error.attemptNumber} 失败，还剩 ${error.retriesLeft} 次重试`);
			
			}
		
		}

);

}



// 调用时自动重试

try {

	const result = await callLLM("写一段代码");
	
	console.log(result);

} catch (error) {

	console.error("重试 3 次后仍然失败：", error);

}

```