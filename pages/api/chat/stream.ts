// Next.js API è·¯ç”±ç±»å‹å®šä¹‰
import type { NextApiRequest, NextApiResponse } from 'next'
// å¯¼å…¥ OpenAI SDKï¼ˆç¡…åŸºæµåŠ¨å…¼å®¹ OpenAI API æ ¼å¼ï¼‰
import OpenAI from 'openai'
// å¯¼å…¥ p-retry ç”¨äºé‡è¯•
import pRetry from 'p-retry'
// å¯¼å…¥ tiktoken ç”¨äºè®¡ç®— token
import { encodingForModel } from 'js-tiktoken'
// å¯¼å…¥é…ç½®
import { DEEPSEEK_API_KEY, DEEPSEEK_API_BASE_URL } from '@/lib/config'

// DeepSeek-V3.2 ä»·æ ¼ï¼ˆå…ƒ/ç™¾ä¸‡tokensï¼‰
const INPUT_PRICE_PER_MILLION = 2
const OUTPUT_PRICE_PER_MILLION = 3

// æ¨¡å‹åç§°
const MODEL_NAME = 'deepseek-ai/DeepSeek-V3.2-Exp'

/**
 * POST /api/chat/stream - æµå¼è°ƒç”¨ç¡…åŸºæµåŠ¨ AI èŠå¤© API
 * 
 * ä½¿ç”¨ Server-Sent Events (SSE) å®ç°æµå¼è¾“å‡º
 * æ”¯æŒ p-retry é‡è¯•ã€token è®¡ç®—ã€æˆæœ¬ç»Ÿè®¡ã€429 é”™è¯¯å¤„ç†
 * 
 * è¯·æ±‚ä½“ï¼š
 * {
 *   "messages": [
 *     { "role": "user", "content": "ç”¨æˆ·æ¶ˆæ¯" }
 *   ]
 * }
 */
export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse
) {
  if (req.method !== 'POST') {
    res.setHeader('Allow', ['POST'])
    return res.status(405).json({
      success: false,
      error: `Method ${req.method} not allowed`
    })
  }

  // éªŒè¯ API Key
  if (!DEEPSEEK_API_KEY) {
    return res.status(500).json({
      success: false,
      error: 'API Key is not configured'
    })
  }

  try {
    const { messages } = req.body

    // éªŒè¯å‚æ•°
    if (!messages || !Array.isArray(messages) || messages.length === 0) {
      return res.status(400).json({
        success: false,
        error: 'messages is required and must be a non-empty array'
      })
    }

    // è®¾ç½® SSE å“åº”å¤´
    res.setHeader('Content-Type', 'text/event-stream')
    res.setHeader('Cache-Control', 'no-cache')
    res.setHeader('Connection', 'keep-alive')
    res.setHeader('X-Accel-Buffering', 'no') // ç¦ç”¨ Nginx ç¼“å†²

    // åˆå§‹åŒ– tiktoken ç¼–ç å™¨ï¼ˆä½¿ç”¨ gpt-4 ç¼–ç ï¼ŒDeepSeek-V3.2 å…¼å®¹ï¼‰
    const encoding = encodingForModel('gpt-4')

    // è®¡ç®—è¾“å…¥ token æ•°
    const inputText = messages.map(m => `${m.role}: ${m.content}`).join('\n')
    const inputTokens = encoding.encode(inputText).length

    // è®¡ç®—è¾“å…¥æˆæœ¬
    const inputCost = (inputTokens / 1_000_000) * INPUT_PRICE_PER_MILLION

    // åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ç¡…åŸºæµåŠ¨ APIï¼‰
    const openai = new OpenAI({
      apiKey: DEEPSEEK_API_KEY,
      baseURL: DEEPSEEK_API_BASE_URL,
      timeout: 120000, // 120ç§’è¶…æ—¶
    })

    // ä½¿ç”¨ p-retry åŒ…è£… API è°ƒç”¨ï¼Œå¤„ç†é‡è¯•é€»è¾‘
    let outputTokens = 0
    let outputText = ''

    await pRetry(
      async () => {
        try {
          // è°ƒç”¨ç¡…åŸºæµåŠ¨ APIï¼Œå¯ç”¨æµå¼è¾“å‡º
          const stream = await openai.chat.completions.create({
            model: MODEL_NAME,
            messages: messages.map((msg: any) => ({
              role: msg.role,
              content: msg.content,
            })),
            temperature: 0.8,
            max_tokens: 65535,
            // seed: 42, // æ³¨é‡Šæ‰ï¼Œç¨åæµ‹è¯•å¼€å¯
            stream: true, // å¯ç”¨æµå¼è¾“å‡º
          })

          // å‘é€åˆå§‹æ¶ˆæ¯ï¼ˆåŒ…å« token ç»Ÿè®¡ä¿¡æ¯ï¼‰
          const startMessage = {
            type: 'start',
            message: 'å¼€å§‹ç”Ÿæˆ...',
            stats: {
              inputTokens,
              inputCost: inputCost.toFixed(6),
            }
          }
          console.log('ğŸ“¤ [API] å‘é€ start æ¶ˆæ¯:', JSON.stringify(startMessage))
          res.write(`data: ${JSON.stringify(startMessage)}\n\n`)

          // å¤„ç†æµå¼å“åº”
          try {
            let chunkCount = 0
            for await (const chunk of stream) {
              const content = chunk.choices[0]?.delta?.content || ''
              
              if (content) {
                outputText += content
                chunkCount++
                // å‘é€æ•°æ®å—
                const chunkMessage = { type: 'chunk', content }
                if (chunkCount % 10 === 0 || chunkCount <= 3) {
                  console.log(`ğŸ“¤ [API] å‘é€ chunk #${chunkCount}ï¼Œå†…å®¹é•¿åº¦: ${content.length}ï¼Œç´¯è®¡è¾“å‡º: ${outputText.length}`)
                }
                res.write(`data: ${JSON.stringify(chunkMessage)}\n\n`)
              }
            }
            console.log(`ğŸ“¤ [API] æµå¼å“åº”å®Œæˆï¼Œå…± ${chunkCount} ä¸ª chunkï¼Œæ€»è¾“å‡ºé•¿åº¦: ${outputText.length}`)
          } catch (streamError: any) {
            // æµå¼è¯»å–è¿‡ç¨‹ä¸­çš„é”™è¯¯
            if (streamError?.status === 429) {
              throw streamError // é‡æ–°æŠ›å‡ºï¼Œè®©å¤–å±‚å¤„ç†
            }
            throw streamError
          }

          // è®¡ç®—è¾“å‡º token æ•°å’Œæˆæœ¬
          outputTokens = encoding.encode(outputText).length
          const outputCost = (outputTokens / 1_000_000) * OUTPUT_PRICE_PER_MILLION
          const totalCost = inputCost + outputCost

          // å‘é€ç»“æŸæ¶ˆæ¯ï¼ˆåŒ…å«å®Œæ•´çš„ç»Ÿè®¡ä¿¡æ¯ï¼‰
          const doneMessage = {
            type: 'done',
            message: 'ç”Ÿæˆå®Œæˆ',
            stats: {
              inputTokens,
              outputTokens,
              totalTokens: inputTokens + outputTokens,
              inputCost: inputCost.toFixed(6),
              outputCost: outputCost.toFixed(6),
              totalCost: totalCost.toFixed(6),
            }
          }
          console.log('ğŸ“¤ [API] å‘é€ done æ¶ˆæ¯:', JSON.stringify(doneMessage))
          res.write(`data: ${JSON.stringify(doneMessage)}\n\n`)
          res.end()
          console.log('âœ… [API] å“åº”æµå·²ç»“æŸ')

        } catch (error: any) {
          // å¤„ç† 429 é”™è¯¯ï¼ˆé™æµï¼‰
          if (error?.status === 429) {
            // ä»é”™è¯¯å¯¹è±¡ä¸­è·å– Retry-After å¤´
            // OpenAI SDK çš„é”™è¯¯å¯¹è±¡ç»“æ„å¯èƒ½ä¸åŒï¼Œå°è¯•å¤šç§æ–¹å¼è·å–
            let retryAfter: string | undefined
            
            // æ–¹å¼1: ä» error.headers è·å–
            if (error?.headers?.['retry-after']) {
              retryAfter = error.headers['retry-after']
            }
            // æ–¹å¼2: ä» error.response?.headers è·å–
            else if (error?.response?.headers?.['retry-after']) {
              retryAfter = error.response.headers['retry-after']
            }
            // æ–¹å¼3: ä» error.response?.headers?.get è·å–
            else if (error?.response?.headers?.get) {
              retryAfter = error.response.headers.get('retry-after') || undefined
            }
            
            if (retryAfter) {
              const waitTime = parseInt(retryAfter) * 1000 // è½¬æ¢ä¸ºæ¯«ç§’
              console.log(`è§¦å‘é™æµï¼Œ${waitTime}ms åé‡è¯• (Retry-After: ${retryAfter})`)
              
              // ç­‰å¾…æŒ‡å®šæ—¶é—´åæŠ›å‡ºé”™è¯¯ï¼Œè®© p-retry é‡è¯•
              await new Promise(resolve => setTimeout(resolve, waitTime))
            } else {
              // å¦‚æœæ²¡æœ‰ Retry-After å¤´ï¼Œç­‰å¾… 5 ç§’
              console.log('è§¦å‘é™æµï¼Œä½†æœªæ‰¾åˆ° Retry-After å¤´ï¼Œ5ç§’åé‡è¯•')
              await new Promise(resolve => setTimeout(resolve, 5000))
            }
            
            // æŠ›å‡ºé”™è¯¯ï¼Œè§¦å‘ p-retry é‡è¯•
            throw new Error(`Rate limit exceeded (429), retrying...`)
          }
          
          // å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
          throw error
        }
      },
      {
        retries: 5, // æœ€å¤šé‡è¯• 5 æ¬¡
        onFailedAttempt: (error) => {
          console.log(`é‡è¯•å°è¯• ${error.attemptNumber}/${error.retriesLeft + error.attemptNumber}ï¼Œé”™è¯¯:`, error)
        },
      }
    )

  } catch (error: any) {
    console.error('Stream error:', error)
    
    // è·å–è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
    let errorMessage = 'æœªçŸ¥é”™è¯¯'
    if (error instanceof Error) {
      errorMessage = error.message
    }
    
    // å¦‚æœæ˜¯ OpenAI API é”™è¯¯ï¼Œå°è¯•è·å–æ›´å¤šä¿¡æ¯
    if (error?.status) {
      errorMessage = `API é”™è¯¯ (${error.status}): ${errorMessage}`
      if (error?.response) {
        try {
          const errorData = await error.response.json()
          errorMessage += ` - ${JSON.stringify(errorData)}`
        } catch (e) {
          // å¿½ç•¥ JSON è§£æé”™è¯¯
        }
      }
    }
    
    // å‘é€é”™è¯¯æ¶ˆæ¯
    if (!res.headersSent) {
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.write(`data: ${JSON.stringify({ 
        type: 'error', 
        error: errorMessage
      })}\n\n`)
    }
    res.end()
  }
}

